{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "from numpy import load\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the datasets for train and test \n",
    "train_data = pd.read_csv('../data/fnc-1/preprocess_train.csv')\n",
    "test_data = pd.read_csv('../data/fnc-1/preprocess_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create term document matrix fo the columns, tf-idf\n",
    "def create_term_document_matrix(df_type, tf, tfidf):\n",
    "    final_array = list()\n",
    "    for i, val in df_type.iterrows():\n",
    "        normalised_articleHeading = val['articleHeading']\n",
    "        normalised_articleBody = val['articleBody']\n",
    "        # Transform article heading to document-term matrix for tf\n",
    "        term_document_matrix_heading_tf = tf.transform([normalised_articleHeading])\n",
    "        # Return a ndarray such that the new shape should be compatible with the original shape\n",
    "        term_document_matrix_heading_tf = term_document_matrix_heading_tf.toarray().reshape(1, -1)\n",
    "        # Transform article body to document-term matrix for tf\n",
    "        term_document_matrix_body_tf = tf.transform([normalised_articleBody])\n",
    "        # Return a ndarray such that the new shape should be compatible with the original shape\n",
    "        term_document_matrix_body_tf = term_document_matrix_body_tf.toarray().reshape(1, -1)\n",
    "        # Transform article heading to document-term matrix for tf-idf \n",
    "        term_document_matrix_heading_tfidf = tfidf.transform([normalised_articleHeading])\n",
    "        # Return the ndarray for the tf-idf of article headings\n",
    "        term_document_matrix_heading_tfidf =  term_document_matrix_heading_tfidf.toarray()\n",
    "        # Transform article body to document-term matrix for tf-idf \n",
    "        term_document_matrix_body_tfidf = tfidf.transform([normalised_articleBody])\n",
    "        # Return the ndarray for the tf-idf of article body\n",
    "        term_document_matrix_body_tfidf =  term_document_matrix_body_tfidf.toarray()\n",
    "        # Get the cosine similarity \n",
    "        term_document_matrix_cosine_similarity = cosine_similarity(term_document_matrix_heading_tfidf, term_document_matrix_body_tfidf)\n",
    "        # Transform into the original shape \n",
    "        term_document_matrix_cosine_similarity = term_document_matrix_cosine_similarity.reshape(1, -1)\n",
    "        # Get the final featured vectors \n",
    "        featured_vectors = np.squeeze(np.c_[term_document_matrix_heading_tf, term_document_matrix_body_tf, term_document_matrix_cosine_similarity])\n",
    "#         featured_vectors = np.squeeze(np.c_[term_document_matrix_heading_tfidf, term_document_matrix_body_tfidf, term_document_matrix_cosine_similarity])\n",
    "        # Append the featured vectors to the final data array \n",
    "        final_array.append(featured_vectors)\n",
    "    # Convert the final array into numpy array \n",
    "    final_array = np.array(final_array)\n",
    "    return final_array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Manually calculating the TF-IDF \n",
    "# def calculate_term_frequency(words, bow):\n",
    "#     tf = dict()\n",
    "#     bowCount = len(bow)\n",
    "#     for word, count in wordDict.items():\n",
    "#         tf[word] = count / float(bowCount)\n",
    "#     return tf\n",
    "\n",
    "# # Calculating the idf values \n",
    "# def calculate_inverse_document_frequency(documents):\n",
    "#     n = len(documents)\n",
    "#     idf = dict.fromkeys(documents[0].keys(), 0)\n",
    "#     for document in documents:\n",
    "#         for word, val in document.items():\n",
    "#             if val > 0:\n",
    "#                 idf[word] += 1    \n",
    "#     for word, val in idf.items():\n",
    "#         idf[word] = math.log(n / float(val))    \n",
    "#     return idf \n",
    "\n",
    "# # Calculating the tf-idf values \n",
    "# def calculateTfidf(tf, idf):\n",
    "#     tfidf = dict()\n",
    "#     for word, val in tf.items():\n",
    "#         tfidf[word] = val * idf[word]\n",
    "#     return tfidf\n",
    "\n",
    "# bagOfWordsA = documentA.split(' ')\n",
    "# bagOfWordsB = documentB.split(' ')\n",
    "# uniqueWords = set(bagOfWordsA).union(set(bagOfWordsB))\n",
    "# numOfWordsA = dict.fromkeys(uniqueWords, 0)\n",
    "# for word in bagOfWordsA:\n",
    "#     numOfWordsA[word] += 1\n",
    "\n",
    "# tfA = calculate_term_frequency(numOfWordsA, bagOfWordsA)\n",
    "# tfB = calculate_term_frequency(numOfWordsB, bagOfWordsB)\n",
    "# idfs = calculate_inverse_document_frequency([numOfWordsA, numOfWordsB])\n",
    "# tfidfA = calculateTfidf(tfA, idfs)\n",
    "# tfidfB = calculateTfidf(tfB, idfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bodyId</th>\n",
       "      <th>articleHeading</th>\n",
       "      <th>articleBody</th>\n",
       "      <th>articleStance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>appl instal safe instor protect gold watch edit</td>\n",
       "      <td>alsisi deni isra report state offer extend gaz...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>elsisi deni claim hell give sinai land palesti...</td>\n",
       "      <td>alsisi deni isra report state offer extend gaz...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>appl keep gold watch edit special instor safe</td>\n",
       "      <td>alsisi deni isra report state offer extend gaz...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>appl store keep gold edit appl watch custom safe</td>\n",
       "      <td>alsisi deni isra report state offer extend gaz...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>south korean woman hair eaten robot vacuum cle...</td>\n",
       "      <td>alsisi deni isra report state offer extend gaz...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bodyId                                     articleHeading  \\\n",
       "0       1    appl instal safe instor protect gold watch edit   \n",
       "1       1  elsisi deni claim hell give sinai land palesti...   \n",
       "2       1      appl keep gold watch edit special instor safe   \n",
       "3       1   appl store keep gold edit appl watch custom safe   \n",
       "4       1  south korean woman hair eaten robot vacuum cle...   \n",
       "\n",
       "                                         articleBody articleStance  \n",
       "0  alsisi deni isra report state offer extend gaz...     unrelated  \n",
       "1  alsisi deni isra report state offer extend gaz...         agree  \n",
       "2  alsisi deni isra report state offer extend gaz...     unrelated  \n",
       "3  alsisi deni isra report state offer extend gaz...     unrelated  \n",
       "4  alsisi deni isra report state offer extend gaz...     unrelated  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neeraj/.local/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/neeraj/.local/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/neeraj/.local/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "/Users/neeraj/.local/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bodyId</th>\n",
       "      <th>articleHeading</th>\n",
       "      <th>articleBody</th>\n",
       "      <th>articleStance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>soldier shot parliament lock gunfir erupt war ...</td>\n",
       "      <td>small meteorit crash wood area nicaragua capit...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>tourist dub spider man spider burrow skin day</td>\n",
       "      <td>small meteorit crash wood area nicaragua capit...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>luke somer kill fail rescu attempt yemen</td>\n",
       "      <td>small meteorit crash wood area nicaragua capit...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>break soldier shot war memori ottawa</td>\n",
       "      <td>small meteorit crash wood area nicaragua capit...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>giant 8ft 9in catfish weigh 19 stone caught it...</td>\n",
       "      <td>small meteorit crash wood area nicaragua capit...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bodyId                                     articleHeading  \\\n",
       "0       0  soldier shot parliament lock gunfir erupt war ...   \n",
       "1       0      tourist dub spider man spider burrow skin day   \n",
       "2       0           luke somer kill fail rescu attempt yemen   \n",
       "3       0               break soldier shot war memori ottawa   \n",
       "4       0  giant 8ft 9in catfish weigh 19 stone caught it...   \n",
       "\n",
       "                                         articleBody articleStance  \n",
       "0  small meteorit crash wood area nicaragua capit...             3  \n",
       "1  small meteorit crash wood area nicaragua capit...             3  \n",
       "2  small meteorit crash wood area nicaragua capit...             3  \n",
       "3  small meteorit crash wood area nicaragua capit...             3  \n",
       "4  small meteorit crash wood area nicaragua capit...             3  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Stances(categorical) into quantitative values for train data where \n",
    "# 0 -> agree\n",
    "# 1 -> disagree\n",
    "# 2 -> discuss\n",
    "# 3 -> unrelated\n",
    "for i, val in enumerate(train_data['articleStance']):\n",
    "    if val == \"agree\":\n",
    "        train_data['articleStance'][i] = 0\n",
    "    elif val == \"disagree\":\n",
    "        train_data['articleStance'][i] = 1\n",
    "    elif val == \"discuss\":\n",
    "        train_data['articleStance'][i] = 2\n",
    "    else:\n",
    "        train_data['articleStance'][i] = 3\n",
    "        \n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neeraj/.local/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/neeraj/.local/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/neeraj/.local/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "/Users/neeraj/.local/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bodyId</th>\n",
       "      <th>articleHeading</th>\n",
       "      <th>articleBody</th>\n",
       "      <th>articleStance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>appl instal safe instor protect gold watch edit</td>\n",
       "      <td>alsisi deni isra report state offer extend gaz...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>elsisi deni claim hell give sinai land palesti...</td>\n",
       "      <td>alsisi deni isra report state offer extend gaz...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>appl keep gold watch edit special instor safe</td>\n",
       "      <td>alsisi deni isra report state offer extend gaz...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>appl store keep gold edit appl watch custom safe</td>\n",
       "      <td>alsisi deni isra report state offer extend gaz...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>south korean woman hair eaten robot vacuum cle...</td>\n",
       "      <td>alsisi deni isra report state offer extend gaz...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bodyId                                     articleHeading  \\\n",
       "0       1    appl instal safe instor protect gold watch edit   \n",
       "1       1  elsisi deni claim hell give sinai land palesti...   \n",
       "2       1      appl keep gold watch edit special instor safe   \n",
       "3       1   appl store keep gold edit appl watch custom safe   \n",
       "4       1  south korean woman hair eaten robot vacuum cle...   \n",
       "\n",
       "                                         articleBody articleStance  \n",
       "0  alsisi deni isra report state offer extend gaz...             3  \n",
       "1  alsisi deni isra report state offer extend gaz...             0  \n",
       "2  alsisi deni isra report state offer extend gaz...             3  \n",
       "3  alsisi deni isra report state offer extend gaz...             3  \n",
       "4  alsisi deni isra report state offer extend gaz...             3  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Stances(categorical) into quantitative values for test data where \n",
    "# 0 -> agree\n",
    "# 1 -> disagree\n",
    "# 2 -> discuss\n",
    "# 3 -> unrelated\n",
    "for i, val in enumerate(test_data['articleStance']):\n",
    "    if val == \"agree\":\n",
    "        test_data['articleStance'][i] = 0\n",
    "    elif val == \"disagree\":\n",
    "        test_data['articleStance'][i] = 1\n",
    "    elif val == \"discuss\":\n",
    "        test_data['articleStance'][i] = 2\n",
    "    else:\n",
    "        test_data['articleStance'][i] = 3\n",
    "        \n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the combined unqiue strings in headings and body\n",
    "def fetch_final_strings_combined(df_type):\n",
    "    final_strings_combined = list()\n",
    "    # Loop over each column and append the values \n",
    "    for i, val in enumerate(df_type['articleHeading']):\n",
    "        if val not in final_strings_combined:\n",
    "            final_strings_combined.append(val)\n",
    "    for i, val in enumerate(df_type['articleBody']):\n",
    "        if val not in final_strings_combined:\n",
    "            final_strings_combined.append(val)\n",
    "    # Return the final combined array of unique strings\n",
    "    return final_strings_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the common vocabulary of strings for train data\n",
    "train_vocabulary = fetch_final_strings_combined(train_data)\n",
    "# Learn vocabulary training set.\n",
    "tf = TfidfVectorizer(max_features = 2500, use_idf = False)\n",
    "count_train_tfvectorizer = tf.fit(train_vocabulary)\n",
    "# Learn vocabulary and idf from training set.\n",
    "tfidf = TfidfVectorizer(max_features = 2500, use_idf = True)\n",
    "count_train_tfidfvectorizer = tfidf.fit(train_vocabulary)\n",
    "# Get the final term document matrix for X_train \n",
    "X_train = create_term_document_matrix(train_data, count_train_tfvectorizer, count_train_tfidfvectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49972, 5001)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of the X_train array\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the common vocabulary of strings for test data\n",
    "# test_vocabulary = fetch_final_strings_combined(test_data)\n",
    "# Learn vocabulary training set.\n",
    "# count_test_tfvectorizer = TfidfVectorizer(max_features = 2500, use_idf = False).fit(test_vocabulary)\n",
    "# Learn vocabulary and idf from training set.\n",
    "# count_test_tfidfvectorizer = TfidfVectorizer(max_features = 2500, use_idf = True).fit(test_vocabulary)\n",
    "# Get the final term document matrix for X_train \n",
    "X_test = create_term_document_matrix(test_data, tf, tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25413, 5001)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the X_train numpy array \n",
    "save('../data/fnc-1/x_train.npy', X_train)\n",
    "# Save the X_test numpy array \n",
    "save('../data/fnc-1/x_test.npy', X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the numpy arrays\n",
    "# X_train = load('../data/fnc-1/x_train.npy')\n",
    "# X_test = load('../data/fnc-1/x_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the Y_train value array and save it\n",
    "Y_train = train_data['articleStance'].values\n",
    "save('../data/fnc-1/y_train.npy', Y_train, allow_pickle=True)\n",
    "type(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the Y_test value array and save it \n",
    "Y_test = test_data['articleStance'].values \n",
    "save('../data/fnc-1/y_test.npy', Y_test, allow_pickle=True)\n",
    "type(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 36545, 0: 3678, 2: 8909, 1: 840})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(train_data['articleStance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 18349, 0: 1903, 2: 4464, 1: 697})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(test_data['articleStance'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
