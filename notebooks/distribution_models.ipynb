{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "from numpy import load\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the datasets for train and test \n",
    "train_data = pd.read_csv('../data/fnc-1/preprocess_train.csv')\n",
    "test_data = pd.read_csv('../data/fnc-1/preprocess_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create term document matrix fo the columns, tf-idf\n",
    "def create_term_document_matrix(df_type, tf, tfidf):\n",
    "    final_array = list()\n",
    "    for i, val in df_type.iterrows():\n",
    "        normalised_articleHeading = val['articleHeading']\n",
    "        normalised_articleBody = val['articleBody']\n",
    "        # Transform article heading to document-term matrix for tf\n",
    "        term_document_matrix_heading_tf = tf.transform([normalised_articleHeading])\n",
    "        # Return a ndarray such that the new shape should be compatible with the original shape\n",
    "        term_document_matrix_heading_tf = term_document_matrix_heading_tf.toarray().reshape(1, -1)\n",
    "        # Transform article body to document-term matrix for tf\n",
    "        term_document_matrix_body_tf = tf.transform([normalised_articleBody])\n",
    "        # Return a ndarray such that the new shape should be compatible with the original shape\n",
    "        term_document_matrix_body_tf = term_document_matrix_body_tf.toarray().reshape(1, -1)\n",
    "        # Transform article heading to document-term matrix for tf-idf \n",
    "        term_document_matrix_heading_tfidf = tfidf.transform([normalised_articleHeading])\n",
    "        # Return the ndarray for the tf-idf of article headings\n",
    "        term_document_matrix_heading_tfidf =  term_document_matrix_heading_tfidf.toarray()\n",
    "        # Transform article body to document-term matrix for tf-idf \n",
    "        term_document_matrix_body_tfidf = tfidf.transform([normalised_articleBody])\n",
    "        # Return the ndarray for the tf-idf of article body\n",
    "        term_document_matrix_body_tfidf =  term_document_matrix_body_tfidf.toarray()\n",
    "        # Get the cosine similarity \n",
    "        term_document_matrix_cosine_similarity = cosine_similarity(term_document_matrix_heading_tfidf, term_document_matrix_body_tfidf)\n",
    "        # Transform into the original shape \n",
    "        term_document_matrix_cosine_similarity = term_document_matrix_cosine_similarity.reshape(1, -1)\n",
    "        # Get the final featured vectors \n",
    "        featured_vectors = np.squeeze(np.c_[term_document_matrix_heading_tf, term_document_matrix_body_tf, term_document_matrix_cosine_similarity])\n",
    "#         featured_vectors = np.squeeze(np.c_[term_document_matrix_heading_tfidf, term_document_matrix_body_tfidf, term_document_matrix_cosine_similarity])\n",
    "        # Append the featured vectors to the final data array \n",
    "        final_array.append(featured_vectors)\n",
    "    # Convert the final array into numpy array \n",
    "    final_array = np.array(final_array)\n",
    "    return final_array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Manually calculating the TF-IDF \n",
    "# def calculate_term_frequency(words, bow):\n",
    "#     tf = dict()\n",
    "#     bowCount = len(bow)\n",
    "#     for word, count in wordDict.items():\n",
    "#         tf[word] = count / float(bowCount)\n",
    "#     return tf\n",
    "\n",
    "# # Calculating the idf values \n",
    "# def calculate_inverse_document_frequency(documents):\n",
    "#     n = len(documents)\n",
    "#     idf = dict.fromkeys(documents[0].keys(), 0)\n",
    "#     for document in documents:\n",
    "#         for word, val in document.items():\n",
    "#             if val > 0:\n",
    "#                 idf[word] += 1    \n",
    "#     for word, val in idf.items():\n",
    "#         idf[word] = math.log(n / float(val))    \n",
    "#     return idf \n",
    "\n",
    "# # Calculating the tf-idf values \n",
    "# def calculateTfidf(tf, idf):\n",
    "#     tfidf = dict()\n",
    "#     for word, val in tf.items():\n",
    "#         tfidf[word] = val * idf[word]\n",
    "#     return tfidf\n",
    "\n",
    "# bagOfWordsA = documentA.split(' ')\n",
    "# bagOfWordsB = documentB.split(' ')\n",
    "# uniqueWords = set(bagOfWordsA).union(set(bagOfWordsB))\n",
    "# numOfWordsA = dict.fromkeys(uniqueWords, 0)\n",
    "# for word in bagOfWordsA:\n",
    "#     numOfWordsA[word] += 1\n",
    "\n",
    "# tfA = calculate_term_frequency(numOfWordsA, bagOfWordsA)\n",
    "# tfB = calculate_term_frequency(numOfWordsB, bagOfWordsB)\n",
    "# idfs = calculate_inverse_document_frequency([numOfWordsA, numOfWordsB])\n",
    "# tfidfA = calculateTfidf(tfA, idfs)\n",
    "# tfidfB = calculateTfidf(tfB, idfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bodyId</th>\n",
       "      <th>articleHeading</th>\n",
       "      <th>articleBody</th>\n",
       "      <th>articleStance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>appl instal safe instor protect gold watch edit</td>\n",
       "      <td>alsisi deni isra report state offer extend gaz...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>elsisi deni claim hell give sinai land palesti...</td>\n",
       "      <td>alsisi deni isra report state offer extend gaz...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>appl keep gold watch edit special instor safe</td>\n",
       "      <td>alsisi deni isra report state offer extend gaz...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>appl store keep gold edit appl watch custom safe</td>\n",
       "      <td>alsisi deni isra report state offer extend gaz...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>south korean woman hair eaten robot vacuum cle...</td>\n",
       "      <td>alsisi deni isra report state offer extend gaz...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bodyId                                     articleHeading  \\\n",
       "0       1    appl instal safe instor protect gold watch edit   \n",
       "1       1  elsisi deni claim hell give sinai land palesti...   \n",
       "2       1      appl keep gold watch edit special instor safe   \n",
       "3       1   appl store keep gold edit appl watch custom safe   \n",
       "4       1  south korean woman hair eaten robot vacuum cle...   \n",
       "\n",
       "                                         articleBody articleStance  \n",
       "0  alsisi deni isra report state offer extend gaz...     unrelated  \n",
       "1  alsisi deni isra report state offer extend gaz...         agree  \n",
       "2  alsisi deni isra report state offer extend gaz...     unrelated  \n",
       "3  alsisi deni isra report state offer extend gaz...     unrelated  \n",
       "4  alsisi deni isra report state offer extend gaz...     unrelated  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neeraj/.local/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/neeraj/.local/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/neeraj/.local/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "/Users/neeraj/.local/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bodyId</th>\n",
       "      <th>articleHeading</th>\n",
       "      <th>articleBody</th>\n",
       "      <th>articleStance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>soldier shot parliament lock gunfir erupt war ...</td>\n",
       "      <td>small meteorit crash wood area nicaragua capit...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>tourist dub spider man spider burrow skin day</td>\n",
       "      <td>small meteorit crash wood area nicaragua capit...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>luke somer kill fail rescu attempt yemen</td>\n",
       "      <td>small meteorit crash wood area nicaragua capit...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>break soldier shot war memori ottawa</td>\n",
       "      <td>small meteorit crash wood area nicaragua capit...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>giant 8ft 9in catfish weigh 19 stone caught it...</td>\n",
       "      <td>small meteorit crash wood area nicaragua capit...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bodyId                                     articleHeading  \\\n",
       "0       0  soldier shot parliament lock gunfir erupt war ...   \n",
       "1       0      tourist dub spider man spider burrow skin day   \n",
       "2       0           luke somer kill fail rescu attempt yemen   \n",
       "3       0               break soldier shot war memori ottawa   \n",
       "4       0  giant 8ft 9in catfish weigh 19 stone caught it...   \n",
       "\n",
       "                                         articleBody articleStance  \n",
       "0  small meteorit crash wood area nicaragua capit...             3  \n",
       "1  small meteorit crash wood area nicaragua capit...             3  \n",
       "2  small meteorit crash wood area nicaragua capit...             3  \n",
       "3  small meteorit crash wood area nicaragua capit...             3  \n",
       "4  small meteorit crash wood area nicaragua capit...             3  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Stances(categorical) into quantitative values for train data where \n",
    "# 0 -> agree\n",
    "# 1 -> disagree\n",
    "# 2 -> discuss\n",
    "# 3 -> unrelated\n",
    "for i, val in enumerate(train_data['articleStance']):\n",
    "    if val == \"agree\":\n",
    "        train_data['articleStance'][i] = 0\n",
    "    elif val == \"disagree\":\n",
    "        train_data['articleStance'][i] = 1\n",
    "    elif val == \"discuss\":\n",
    "        train_data['articleStance'][i] = 2\n",
    "    else:\n",
    "        train_data['articleStance'][i] = 3\n",
    "        \n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neeraj/.local/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/neeraj/.local/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/neeraj/.local/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "/Users/neeraj/.local/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bodyId</th>\n",
       "      <th>articleHeading</th>\n",
       "      <th>articleBody</th>\n",
       "      <th>articleStance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>appl instal safe instor protect gold watch edit</td>\n",
       "      <td>alsisi deni isra report state offer extend gaz...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>elsisi deni claim hell give sinai land palesti...</td>\n",
       "      <td>alsisi deni isra report state offer extend gaz...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>appl keep gold watch edit special instor safe</td>\n",
       "      <td>alsisi deni isra report state offer extend gaz...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>appl store keep gold edit appl watch custom safe</td>\n",
       "      <td>alsisi deni isra report state offer extend gaz...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>south korean woman hair eaten robot vacuum cle...</td>\n",
       "      <td>alsisi deni isra report state offer extend gaz...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bodyId                                     articleHeading  \\\n",
       "0       1    appl instal safe instor protect gold watch edit   \n",
       "1       1  elsisi deni claim hell give sinai land palesti...   \n",
       "2       1      appl keep gold watch edit special instor safe   \n",
       "3       1   appl store keep gold edit appl watch custom safe   \n",
       "4       1  south korean woman hair eaten robot vacuum cle...   \n",
       "\n",
       "                                         articleBody articleStance  \n",
       "0  alsisi deni isra report state offer extend gaz...             3  \n",
       "1  alsisi deni isra report state offer extend gaz...             0  \n",
       "2  alsisi deni isra report state offer extend gaz...             3  \n",
       "3  alsisi deni isra report state offer extend gaz...             3  \n",
       "4  alsisi deni isra report state offer extend gaz...             3  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Stances(categorical) into quantitative values for test data where \n",
    "# 0 -> agree\n",
    "# 1 -> disagree\n",
    "# 2 -> discuss\n",
    "# 3 -> unrelated\n",
    "for i, val in enumerate(test_data['articleStance']):\n",
    "    if val == \"agree\":\n",
    "        test_data['articleStance'][i] = 0\n",
    "    elif val == \"disagree\":\n",
    "        test_data['articleStance'][i] = 1\n",
    "    elif val == \"discuss\":\n",
    "        test_data['articleStance'][i] = 2\n",
    "    else:\n",
    "        test_data['articleStance'][i] = 3\n",
    "        \n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the combined unqiue strings in headings and body\n",
    "def fetch_final_strings_combined(df_type):\n",
    "    final_strings_combined = list()\n",
    "    # Loop over each column and append the values \n",
    "    for i, val in enumerate(df_type['articleHeading']):\n",
    "        if val not in final_strings_combined:\n",
    "            final_strings_combined.append(val)\n",
    "    for i, val in enumerate(df_type['articleBody']):\n",
    "        if val not in final_strings_combined:\n",
    "            final_strings_combined.append(val)\n",
    "    # Return the final combined array of unique strings\n",
    "    return final_strings_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the common vocabulary of strings for train data\n",
    "train_vocabulary = fetch_final_strings_combined(train_data)\n",
    "# Learn vocabulary training set.\n",
    "tf = TfidfVectorizer(max_features = 2500, use_idf = False)\n",
    "count_train_tfvectorizer = tf.fit(train_vocabulary)\n",
    "# Learn vocabulary and idf from training set.\n",
    "tfidf = TfidfVectorizer(max_features = 2500, use_idf = True)\n",
    "count_train_tfidfvectorizer = tfidf.fit(train_vocabulary)\n",
    "# Get the final term document matrix for X_train \n",
    "X_train = create_term_document_matrix(train_data, count_train_tfvectorizer, count_train_tfidfvectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49972, 5001)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of the X_train array\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the common vocabulary of strings for test data\n",
    "# test_vocabulary = fetch_final_strings_combined(test_data)\n",
    "# Learn vocabulary training set.\n",
    "# count_test_tfvectorizer = TfidfVectorizer(max_features = 2500, use_idf = False).fit(test_vocabulary)\n",
    "# Learn vocabulary and idf from training set.\n",
    "# count_test_tfidfvectorizer = TfidfVectorizer(max_features = 2500, use_idf = True).fit(test_vocabulary)\n",
    "# Get the final term document matrix for X_train \n",
    "X_test = create_term_document_matrix(test_data, tf, tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25413, 5001)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the X_train numpy array \n",
    "save('../data/fnc-1/x_train.npy', X_train)\n",
    "# Save the X_test numpy array \n",
    "save('../data/fnc-1/x_test.npy', X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the numpy arrays\n",
    "# X_train = load('../data/fnc-1/x_train.npy')\n",
    "# X_test = load('../data/fnc-1/x_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the Y_train value array and save it\n",
    "Y_train = train_data['articleStance'].values\n",
    "save('../data/fnc-1/y_train.npy', Y_train, allow_pickle=True)\n",
    "type(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the Y_test value array and save it \n",
    "Y_test = test_data['articleStance'].values \n",
    "save('../data/fnc-1/y_test.npy', Y_test, allow_pickle=True)\n",
    "type(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 36545, 0: 3678, 2: 8909, 1: 840})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(train_data['articleStance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 18349, 0: 1903, 2: 4464, 1: 697})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(test_data['articleStance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xx['vector'] = np.array(X_train, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['vector'] = [0] * len(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neeraj/.local/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/neeraj/miniconda3/lib/python3.7/site-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train_data)):\n",
    "    new_df['vector'][i] = np.array(X_train[i], dtype=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bodyId</th>\n",
       "      <th>articleHeading</th>\n",
       "      <th>articleBody</th>\n",
       "      <th>articleStance</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78</td>\n",
       "      <td>batmobil stolen batman v superman dawn justic ...</td>\n",
       "      <td>rumour ridicul pretti amus hard believ given z...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83</td>\n",
       "      <td>weather report caught write name snow readi go...</td>\n",
       "      <td>there readi go camera there realli realli read...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124</td>\n",
       "      <td>peni spraypaint 25 million car prank video</td>\n",
       "      <td>might say matter rich spend 25 million car mak...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>176</td>\n",
       "      <td>whoa paul rudd one airport hero took homophob</td>\n",
       "      <td>hunki mensch took violent bulli look like paul...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>218</td>\n",
       "      <td>pope franci turn made pet heaven comment</td>\n",
       "      <td>leader cathol church assur pet lover across wo...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8395</th>\n",
       "      <td>2515</td>\n",
       "      <td>stori cathol priest die see god woman come bac...</td>\n",
       "      <td>et si dieu tait une femm cest ce quaffirm le p...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8396</th>\n",
       "      <td>2515</td>\n",
       "      <td>ope hoax priest never exist claim die saw fema...</td>\n",
       "      <td>et si dieu tait une femm cest ce quaffirm le p...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8397</th>\n",
       "      <td>2519</td>\n",
       "      <td>batmobil stolen batman v superman dawn justic ...</td>\n",
       "      <td>friday rumor crop one new batmobil vehicl stol...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8398</th>\n",
       "      <td>2521</td>\n",
       "      <td>nasa confirm earth experi 6 day total dark dec...</td>\n",
       "      <td>hoax stori circul far wide twitter facebook ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8399</th>\n",
       "      <td>2529</td>\n",
       "      <td>rumor debunk robocopstyl robot patrol microsof...</td>\n",
       "      <td>dalek know fear must fear cold calcul robot dr...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8400 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      bodyId                                     articleHeading  \\\n",
       "0         78  batmobil stolen batman v superman dawn justic ...   \n",
       "1         83  weather report caught write name snow readi go...   \n",
       "2        124         peni spraypaint 25 million car prank video   \n",
       "3        176      whoa paul rudd one airport hero took homophob   \n",
       "4        218           pope franci turn made pet heaven comment   \n",
       "...      ...                                                ...   \n",
       "8395    2515  stori cathol priest die see god woman come bac...   \n",
       "8396    2515  ope hoax priest never exist claim die saw fema...   \n",
       "8397    2519  batmobil stolen batman v superman dawn justic ...   \n",
       "8398    2521  nasa confirm earth experi 6 day total dark dec...   \n",
       "8399    2529  rumor debunk robocopstyl robot patrol microsof...   \n",
       "\n",
       "                                            articleBody articleStance  \\\n",
       "0     rumour ridicul pretti amus hard believ given z...             1   \n",
       "1     there readi go camera there realli realli read...             1   \n",
       "2     might say matter rich spend 25 million car mak...             1   \n",
       "3     hunki mensch took violent bulli look like paul...             1   \n",
       "4     leader cathol church assur pet lover across wo...             1   \n",
       "...                                                 ...           ...   \n",
       "8395  et si dieu tait une femm cest ce quaffirm le p...             1   \n",
       "8396  et si dieu tait une femm cest ce quaffirm le p...             1   \n",
       "8397  friday rumor crop one new batmobil vehicl stol...             1   \n",
       "8398  hoax stori circul far wide twitter facebook ma...             1   \n",
       "8399  dalek know fear must fear cold calcul robot dr...             1   \n",
       "\n",
       "                                                 vector  \n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "...                                                 ...  \n",
       "8395  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "8396  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "8397  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "8398  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "8399  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "\n",
       "[8400 rows x 5 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_disagree_df = new_df[new_df.articleStance == 1]\n",
    "temp_df = pd.DataFrame().append([new_disagree_df] * 10, ignore_index=True)\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0 0.0 0.0 ... 0.0 0.0 0.5622893760998064]\n",
      "[ 282  283  643 1255 1284 1995 2051 2125 2170 2541 2584 2591 2622 2637\n",
      " 2718 2758 2782 2783 2800 2801 2807 2829 2866 2963 2968 3004 3007 3056\n",
      " 3081 3126 3143 3196 3271 3304 3326 3375 3413 3422 3442 3462 3472 3475\n",
      " 3494 3501 3514 3518 3562 3576 3586 3632 3645 3755 3805 3853 3950 3969\n",
      " 3979 3996 4059 4084 4085 4086 4095 4193 4226 4229 4240 4244 4315 4355\n",
      " 4395 4423 4429 4431 4444 4470 4491 4495 4501 4510 4551 4561 4577 4595\n",
      " 4613 4625 4631 4638 4670 4745 4746 4773 4848 4855 4869 4872 4879 4926\n",
      " 4931 5000]\n",
      "[-2 -2  1 -1 -2 -1 -1 -2 -2  1  0 -1  0 -1  0  1  1  1  0  1 -1 -2 -1 -2\n",
      "  1 -1  1  1 -1 -2  0  1  1 -1 -2 -1  1 -2  0  0  1  0  0  1 -2 -1 -2 -1\n",
      " -2 -2 -1  0  1  1 -2 -2 -2 -2  1  0  1 -2  0  0 -1 -1  1  0  1 -2  0 -1\n",
      "  0  0 -2 -2 -1 -2  1 -2  1  1  1 -1 -1 -2 -2  0  0  1 -2 -1  0 -1 -1  0\n",
      " -2  0  0 -1]\n",
      "[0.0 0.0 0.0 ... 0.0 0.0 -0.43771062390019355]\n",
      "[0.0 0.0 0.0 ... 0.0 0.0 0.43771062390019355]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "5001\n",
      "[0.0 0.0 0.0 ... 0.0 0.0 0.32518383187630595]\n",
      "[ 402  436 1007 1513 1819 1863 2049 2348 2416 2474 2595 2629 2735 2761\n",
      " 2822 2865 2902 2924 3001 3059 3068 3074 3092 3263 3326 3351 3507 3575\n",
      " 3601 3712 3843 3853 3867 3871 3893 3944 3956 3983 4013 4036 4046 4047\n",
      " 4053 4062 4158 4166 4279 4319 4322 4363 4397 4414 4422 4431 4474 4549\n",
      " 4587 4613 4632 4701 4739 4741 4746 4835 4848 4909 4916 4917 4921 4942\n",
      " 4960 4974 5000]\n",
      "[-1  1  0  0 -2 -2 -1  1  0  1  0  0  1  0  0 -2 -1 -1  1 -2 -2 -1  0  1\n",
      " -1 -1 -2  1 -2  1 -2  1 -2 -2  0  1 -1  0  1  0 -1  1  1 -1  1  0 -2 -2\n",
      "  1  0  1 -2 -2 -1  0 -1 -2  0  0  1  1  1 -2 -2  0 -2  0 -2 -2 -1 -2  0\n",
      " -1]\n",
      "[0.0 0.0 0.0 ... 0.0 0.0 -0.674816168123694]\n",
      "[0.0 0.0 0.0 ... 0.0 0.0 0.674816168123694]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "5001\n",
      "[0.0 0.0 0.0 ... 0.0 0.0 0.4676221672341444]\n",
      "[  34  419 1462 1650 1715 2379 2524 2534 2697 2787 2861 2882 2919 3033\n",
      " 3155 3349 3525 3526 3548 3619 3645 3732 3852 3893 3920 3940 3955 3957\n",
      " 3962 4010 4013 4034 4095 4124 4133 4150 4154 4212 4240 4245 4291 4393\n",
      " 4444 4516 4561 4574 4590 4623 4638 4775 4777 4863 4874 4962 5000]\n",
      "[-2 -2  0 -2  0 -2  0  0 -2 -1 -1 -2 -1 -1 -1  0  0 -2 -1  1  0 -2 -2  1\n",
      "  0  1 -1 -2  0  0 -1 -2 -2  1 -2  0 -2  1  0 -2  0 -2  1  1  1  1  0  1\n",
      "  1 -1 -2 -2  1  0  1]\n",
      "[0.0 0.0 0.0 ... 0.0 0.0 1.4676221672341443]\n",
      "[0.0 0.0 0.0 ... 0.0 0.0 1.4676221672341443]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "5001\n"
     ]
    }
   ],
   "source": [
    "for i, row in temp_df.iterrows():\n",
    "    if i < 3:\n",
    "        vectors = np.array(row['vector'])\n",
    "        print(vectors)\n",
    "        nonzero_index = vectors.nonzero()[0]\n",
    "        print(nonzero_index)\n",
    "        random_vec = np.random.randint(-2, 2, len(nonzero_index))\n",
    "        print(random_vec)\n",
    "        vectors[nonzero_index] += random_vec\n",
    "        print(vectors)\n",
    "        # Taking the absolute valyes to remove the negative ones\n",
    "        vectors = np.abs(vectors) \n",
    "        print(vectors)\n",
    "        row['vector'] = vectors.tolist()\n",
    "        print('\\n\\n\\n')\n",
    "        print(len(vectors.tolist()))\n",
    "    else:\n",
    "        break\n",
    "new_df = pd.concat([new_df, temp_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bodyId</th>\n",
       "      <th>articleHeading</th>\n",
       "      <th>articleBody</th>\n",
       "      <th>articleStance</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>soldier shot parliament lock gunfir erupt war ...</td>\n",
       "      <td>small meteorit crash wood area nicaragua capit...</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>tourist dub spider man spider burrow skin day</td>\n",
       "      <td>small meteorit crash wood area nicaragua capit...</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>luke somer kill fail rescu attempt yemen</td>\n",
       "      <td>small meteorit crash wood area nicaragua capit...</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>break soldier shot war memori ottawa</td>\n",
       "      <td>small meteorit crash wood area nicaragua capit...</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>giant 8ft 9in catfish weigh 19 stone caught it...</td>\n",
       "      <td>small meteorit crash wood area nicaragua capit...</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8395</th>\n",
       "      <td>2515</td>\n",
       "      <td>stori cathol priest die see god woman come bac...</td>\n",
       "      <td>et si dieu tait une femm cest ce quaffirm le p...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8396</th>\n",
       "      <td>2515</td>\n",
       "      <td>ope hoax priest never exist claim die saw fema...</td>\n",
       "      <td>et si dieu tait une femm cest ce quaffirm le p...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8397</th>\n",
       "      <td>2519</td>\n",
       "      <td>batmobil stolen batman v superman dawn justic ...</td>\n",
       "      <td>friday rumor crop one new batmobil vehicl stol...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8398</th>\n",
       "      <td>2521</td>\n",
       "      <td>nasa confirm earth experi 6 day total dark dec...</td>\n",
       "      <td>hoax stori circul far wide twitter facebook ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8399</th>\n",
       "      <td>2529</td>\n",
       "      <td>rumor debunk robocopstyl robot patrol microsof...</td>\n",
       "      <td>dalek know fear must fear cold calcul robot dr...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58372 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      bodyId                                     articleHeading  \\\n",
       "0          0  soldier shot parliament lock gunfir erupt war ...   \n",
       "1          0      tourist dub spider man spider burrow skin day   \n",
       "2          0           luke somer kill fail rescu attempt yemen   \n",
       "3          0               break soldier shot war memori ottawa   \n",
       "4          0  giant 8ft 9in catfish weigh 19 stone caught it...   \n",
       "...      ...                                                ...   \n",
       "8395    2515  stori cathol priest die see god woman come bac...   \n",
       "8396    2515  ope hoax priest never exist claim die saw fema...   \n",
       "8397    2519  batmobil stolen batman v superman dawn justic ...   \n",
       "8398    2521  nasa confirm earth experi 6 day total dark dec...   \n",
       "8399    2529  rumor debunk robocopstyl robot patrol microsof...   \n",
       "\n",
       "                                            articleBody articleStance  \\\n",
       "0     small meteorit crash wood area nicaragua capit...             3   \n",
       "1     small meteorit crash wood area nicaragua capit...             3   \n",
       "2     small meteorit crash wood area nicaragua capit...             3   \n",
       "3     small meteorit crash wood area nicaragua capit...             3   \n",
       "4     small meteorit crash wood area nicaragua capit...             3   \n",
       "...                                                 ...           ...   \n",
       "8395  et si dieu tait une femm cest ce quaffirm le p...             1   \n",
       "8396  et si dieu tait une femm cest ce quaffirm le p...             1   \n",
       "8397  friday rumor crop one new batmobil vehicl stol...             1   \n",
       "8398  hoax stori circul far wide twitter facebook ma...             1   \n",
       "8399  dalek know fear must fear cold calcul robot dr...             1   \n",
       "\n",
       "                                                 vector  \n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "...                                                 ...  \n",
       "8395  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "8396  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "8397  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "8398  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "8399  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "\n",
       "[58372 rows x 5 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
