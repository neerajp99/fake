{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from numpy import load\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the X_train, Y_train, X_test and Y_test\n",
    "X_train = np.load('../data/fnc-1/x_train_doc2vec.npy')\n",
    "X_test = np.load('../data/fnc-1/x_test_doc2vec.npy')\n",
    "Y_train = np.load('../data/fnc-1/y_train.npy', allow_pickle=True)\n",
    "Y_test = load('../data/fnc-1/y_test.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the labels into int type to prevent unknown type error \n",
    "Y_train = Y_train.astype('int')\n",
    "Y_test = Y_test.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  72.00251839609648 %\n",
      "Confusion Matrix:\n",
      " [[    2     0   158  1743]\n",
      " [    0     0    89   608]\n",
      " [    0     0   266  4198]\n",
      " [    0     0   319 18030]]\n",
      "Precision Score:  0.7200251839609648\n",
      "Recall Score:  0.7200251839609648\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00      1903\n",
      "           1       0.00      0.00      0.00       697\n",
      "           2       0.32      0.06      0.10      4464\n",
      "           3       0.73      0.98      0.84     18349\n",
      "\n",
      "    accuracy                           0.72     25413\n",
      "   macro avg       0.51      0.26      0.24     25413\n",
      "weighted avg       0.66      0.72      0.62     25413\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neeraj/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier \n",
    "randomForest = RandomForestClassifier(random_state=1)\n",
    "randomForest.fit(X_train, Y_train)\n",
    "Y_predictions = randomForest.predict(X_test)\n",
    "print('Accuracy: ', accuracy_score(Y_test, Y_predictions) * 100, \"%\")\n",
    "# Getting the confusion matrix\n",
    "print('Confusion Matrix:\\n', confusion_matrix(Y_test, Y_predictions))\n",
    "# Precision score\n",
    "print('Precision Score: ', precision_score(Y_test, Y_predictions, average=\"micro\"))\n",
    "# Recall score\n",
    "print('Recall Score: ', recall_score(Y_test, Y_predictions, average=\"micro\"))\n",
    "print(classification_report(Y_test, Y_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  72.05760831070712 %\n",
      "Confusion Matrix:\n",
      " [[   69    16    82  1736]\n",
      " [   50     9    40   598]\n",
      " [   36     6   209  4213]\n",
      " [   37     8   279 18025]]\n",
      "Precision Score:  0.7205760831070712\n",
      "Recall Score:  0.7205760831070712\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.04      0.07      1903\n",
      "           1       0.23      0.01      0.02       697\n",
      "           2       0.34      0.05      0.08      4464\n",
      "           3       0.73      0.98      0.84     18349\n",
      "\n",
      "    accuracy                           0.72     25413\n",
      "   macro avg       0.42      0.27      0.25     25413\n",
      "weighted avg       0.62      0.72      0.63     25413\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neeraj/.local/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Logitsic Regression Classifier \n",
    "logisticRegression = LogisticRegression(solver='saga', multi_class='multinomial')\n",
    "logisticRegression.fit(X_train, Y_train)\n",
    "lr_Y_predictions = logisticRegression.predict(X_test)\n",
    "print('Accuracy: ', accuracy_score(Y_test, lr_Y_predictions) * 100, \"%\")\n",
    "# Getting the confusion matrix\n",
    "print('Confusion Matrix:\\n', confusion_matrix(Y_test, lr_Y_predictions))\n",
    "# Precision score\n",
    "print('Precision Score: ', precision_score(Y_test, lr_Y_predictions, average=\"micro\"))\n",
    "# Recall score\n",
    "print('Recall Score: ', recall_score(Y_test, lr_Y_predictions, average=\"micro\"))\n",
    "print(classification_report(Y_test, lr_Y_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  60.48085625467281 %\n",
      "Confusion Matrix:\n",
      " [[  113    75   523  1192]\n",
      " [   40    60   214   383]\n",
      " [  297   169  1179  2819]\n",
      " [  579   737  3015 14018]]\n",
      "Precision Score:  0.6048085625467281\n",
      "Recall Score:  0.6048085625467281\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.06      0.08      1903\n",
      "           1       0.06      0.09      0.07       697\n",
      "           2       0.24      0.26      0.25      4464\n",
      "           3       0.76      0.76      0.76     18349\n",
      "\n",
      "    accuracy                           0.60     25413\n",
      "   macro avg       0.29      0.29      0.29     25413\n",
      "weighted avg       0.60      0.60      0.60     25413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes Classifier \n",
    "gaussianNB = GaussianNB()\n",
    "gaussianNB.fit(X_train, Y_train)\n",
    "gnb_Y_predictions = gaussianNB.predict(X_test)\n",
    "print('Accuracy: ', accuracy_score(Y_test, gnb_Y_predictions) * 100, \"%\")\n",
    "# Getting the confusion matrix\n",
    "print('Confusion Matrix:\\n', confusion_matrix(Y_test, gnb_Y_predictions))\n",
    "# Precision score\n",
    "print('Precision Score: ', precision_score(Y_test, gnb_Y_predictions, average=\"micro\"))\n",
    "# Recall score\n",
    "print('Recall Score: ', recall_score(Y_test, gnb_Y_predictions, average=\"micro\"))\n",
    "print(classification_report(Y_test, gnb_Y_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  60.48085625467281 %\n",
      "Confusion Matrix:\n",
      " [[  259    61   606   977]\n",
      " [  115    49   222   311]\n",
      " [  432    65  1783  2184]\n",
      " [ 1009   182  4011 13147]]\n",
      "Precision Score:  0.5996143705977256\n",
      "Recall Score:  0.5996143705977256\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.14      0.14      1903\n",
      "           1       0.14      0.07      0.09       697\n",
      "           2       0.27      0.40      0.32      4464\n",
      "           3       0.79      0.72      0.75     18349\n",
      "\n",
      "    accuracy                           0.60     25413\n",
      "   macro avg       0.34      0.33      0.33     25413\n",
      "weighted avg       0.63      0.60      0.61     25413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli Naive Bayes Classifier \n",
    "bernoilliNB = BernoulliNB()\n",
    "bernoilliNB.fit(X_train, Y_train)\n",
    "bnb_Y_predictions = bernoilliNB.predict(X_test)\n",
    "print('Accuracy: ', accuracy_score(Y_test, gnb_Y_predictions) * 100, \"%\")\n",
    "# Getting the confusion matrix\n",
    "print('Confusion Matrix:\\n', confusion_matrix(Y_test, bnb_Y_predictions))\n",
    "# Precision score\n",
    "print('Precision Score: ', precision_score(Y_test, bnb_Y_predictions, average=\"micro\"))\n",
    "# Recall score\n",
    "print('Recall Score: ', recall_score(Y_test, bnb_Y_predictions, average=\"micro\"))\n",
    "print(classification_report(Y_test, bnb_Y_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  57.10069649392043 %\n",
      "Confusion Matrix:\n",
      " [[  208    53   410  1232]\n",
      " [   76    21   190   410]\n",
      " [  472   116  1009  2867]\n",
      " [ 1491   335  3250 13273]]\n",
      "Precision Score:  0.5710069649392043\n",
      "Recall Score:  0.5710069649392043\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.11      0.10      1903\n",
      "           1       0.04      0.03      0.03       697\n",
      "           2       0.21      0.23      0.22      4464\n",
      "           3       0.75      0.72      0.73     18349\n",
      "\n",
      "    accuracy                           0.57     25413\n",
      "   macro avg       0.27      0.27      0.27     25413\n",
      "weighted avg       0.58      0.57      0.58     25413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier \n",
    "decisionTree = DecisionTreeClassifier(random_state=1)\n",
    "decisionTree.fit(X_train, Y_train )\n",
    "dt_Y_predictions = decisionTree.predict(X_test)\n",
    "print('Accuracy: ', accuracy_score(Y_test, dt_Y_predictions) * 100, \"%\")\n",
    "# Getting the confusion matrix\n",
    "print('Confusion Matrix:\\n', confusion_matrix(Y_test, dt_Y_predictions))\n",
    "# Precision score\n",
    "print('Precision Score: ', precision_score(Y_test, dt_Y_predictions, average=\"micro\"))\n",
    "# Recall score\n",
    "print('Recall Score: ', recall_score(Y_test, dt_Y_predictions, average=\"micro\"))\n",
    "print(classification_report(Y_test, dt_Y_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LinearSVC Classifier \n",
    "# linearSVC = LinearSVC(multi_class='crammer_singer', C=0.5)\n",
    "# linearSVC.fit(X_train, Y_train )\n",
    "# lsvc_Y_predictions = linearSVC.predict(X_test)\n",
    "# print('Accuracy: ', accuracy_score(Y_test, lsvc_Y_predictions) * 100, \"%\")\n",
    "# # Getting the confusion matrix\n",
    "# print('Confusion Matrix:\\n', confusion_matrix(Y_test, lsvc_Y_predictions))\n",
    "# # Precision score\n",
    "# print('Precision Score: ', precision_score(Y_test, lsvc_Y_predictions, average=\"micro\"))\n",
    "# # Recall score\n",
    "# print('Recall Score: ', recall_score(Y_test, lsvc_Y_predictions, average=\"micro\"))\n",
    "# print(classification_report(Y_test, lsvc_Y_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  62.86546255853304 %\n",
      "Confusion Matrix:\n",
      " [[  207    24   330  1342]\n",
      " [   89     9   117   482]\n",
      " [  355    41   923  3145]\n",
      " [  950   122  2440 14837]]\n",
      "Precision Score:  0.6286546255853304\n",
      "Recall Score:  0.6286546255853304\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.11      0.12      1903\n",
      "           1       0.05      0.01      0.02       697\n",
      "           2       0.24      0.21      0.22      4464\n",
      "           3       0.75      0.81      0.78     18349\n",
      "\n",
      "    accuracy                           0.63     25413\n",
      "   macro avg       0.29      0.28      0.28     25413\n",
      "weighted avg       0.59      0.63      0.61     25413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MLP Classifier(Neural Net)\n",
    "mlpClassifier = MLPClassifier(random_state=1)\n",
    "mlpClassifier.fit(X_train, Y_train )\n",
    "mlp_Y_predictions = mlpClassifier.predict(X_test)\n",
    "print('Accuracy: ', accuracy_score(Y_test, mlp_Y_predictions) * 100, \"%\")\n",
    "# Getting the confusion matrix\n",
    "print('Confusion Matrix:\\n', confusion_matrix(Y_test, mlp_Y_predictions))\n",
    "# Precision score\n",
    "print('Precision Score: ', precision_score(Y_test, mlp_Y_predictions, average=\"micro\"))\n",
    "# Recall score\n",
    "print('Recall Score: ', recall_score(Y_test, mlp_Y_predictions, average=\"micro\"))\n",
    "print(classification_report(Y_test, mlp_Y_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = ['Random Forest', 'Logistic Regression', 'Gaussian NB', 'Bernoulli NB', 'Decision Tree', 'MLP']\n",
    "rf_accuracy = accuracy_score(Y_test, Y_predictions) * 100 \n",
    "lr_accuracy = accuracy_score(Y_test, lr_Y_predictions) * 100\n",
    "gnb_accuracy = accuracy_score(Y_test, gnb_Y_predictions) * 100\n",
    "bnb_accuracy = accuracy_score(Y_test, bnb_Y_predictions) * 100\n",
    "dt_accuracy = accuracy_score(Y_test, dt_Y_predictions) * 100\n",
    "# lsvc_accuracy = accuracy_score(Y_test, lsvc_Y_predictions) * 100\n",
    "mlp_accuracy = accuracy_score(Y_test, mlp_Y_predictions) * 100\n",
    "models_accuracy = [rf_accuracy, lr_accuracy, gnb_accuracy, bnb_accuracy, dt_accuracy,mlp_accuracy]\n",
    "summary = {'model': models_list, 'accuracy': models_accuracy}\n",
    "models_summary = pd.DataFrame(summary)\n",
    "models_summary.set_index('model', inplace=True)\n",
    "models_summary.index.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>72.002518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>72.057608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian NB</th>\n",
       "      <td>60.480856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli NB</th>\n",
       "      <td>59.961437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>57.100696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>62.865463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      accuracy\n",
       "Random Forest        72.002518\n",
       "Logistic Regression  72.057608\n",
       "Gaussian NB          60.480856\n",
       "Bernoulli NB         59.961437\n",
       "Decision Tree        57.100696\n",
       "MLP                  62.865463"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
